{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-955b8ee68097>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# from sklearn.ensemble import RandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasetUCI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0menvs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLalEnvTargetAccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# depending on the classification model use, we might need to import other packages\n",
    "# from sklearn import svm\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from datasets_orig import DatasetUCI\n",
    "from envs import LalEnvTargetAccuracy\n",
    "\n",
    "from helpers import Minibatch, ReplayBuffer\n",
    "from dqn import DQN\n",
    "from Test_AL import policy_rl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STATE_ESTIMATION = 30\n",
    "SIZE = 100\n",
    "# if we want to train and test RL on the same dataset, use even and odd datapoints for training and testing correspondingly\n",
    "SUBSET = -1 # -1 for using all datapoints, 0 for even, 1 for odd\n",
    "N_JOBS = 1 # can set more if we want to parallelise\n",
    "# remove the dataset that will be used for testing\n",
    "# ['australian', 'breast_cancer', 'diabetis', 'flare_solar', 'german', 'heart', 'mushrooms', 'waveform', 'wdbc']\n",
    "possible_dataset_names = ['breast_cancer', 'diabetis', 'flare_solar', \n",
    "                          'german', 'heart', 'mushrooms', 'waveform', 'wdbc']\n",
    "test_dataset_names = ['australian']\n",
    "# The quality is measures according to a given quality measure `quality_method`. \n",
    "QUALITY_METHOD = metrics.accuracy_score\n",
    "# The `tolerance_level` is the proportion of max quality that needs to be achived in order to terminate an episode. \n",
    "TOLERANCE_LEVEL = 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise a dataset that will contain a sample of datapoint from one the indicated classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetUCI(possible_dataset_names, n_state_estimation=N_STATE_ESTIMATION, subset=SUBSET, size=SIZE)\n",
    "# if we want to measure test error along with training\n",
    "dataset_test = DatasetUCI(test_dataset_names, n_state_estimation=N_STATE_ESTIMATION, subset=1, size=SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise a model that would be used for training a classifier. <br>\n",
    "It can be, for example, Logistic regression: <br>\n",
    "`LogisticRegression(n_jobs=N_JOBS)` <br>\n",
    "SVM: <br>\n",
    "`svm.SVC(probability=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = LalEnvTargetAccuracy(dataset, model, quality_method=QUALITY_METHOD, tolerance_level=TOLERANCE_LEVEL)\n",
    "env_test = LalEnvTargetAccuracy(dataset_test, model, quality_method=QUALITY_METHOD, tolerance_level=TOLERANCE_LEVEL)\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for training RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRNAME = './agents/1-australian-logreg-8-to-1/' # The resulting agent of this experiment will be written in a file\n",
    "\n",
    "# Replay buffer parameters.\n",
    "REPLAY_BUFFER_SIZE = 1e4\n",
    "PRIOROTIZED_REPLAY_EXPONENT = 3\n",
    "\n",
    "# Agent parameters.\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "TARGET_COPY_FACTOR = 0.01\n",
    "BIAS_INITIALIZATION = 0 # default 0 # will be set to minus half of average duration during warm start experiemnts\n",
    "\n",
    "# Warm start parameters.\n",
    "WARM_START_EPISODES = 128 # reduce for test\n",
    "NN_UPDATES_PER_WARM_START = 100\n",
    "\n",
    "# Episode simulation parameters.\n",
    "EPSILON_START = 1\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_STEPS = 1000\n",
    "\n",
    "# Training parameters\n",
    "TRAINING_ITERATIONS = 1000 # reduce for test\n",
    "TRAINING_EPISODES_PER_ITERATION = 10 # at each training ietration x episodes are simulated\n",
    "NN_UPDATES_PER_ITERATION = 60 # at each training iteration x gradient steps are made\n",
    "\n",
    "# Validation and test parameters\n",
    "N_VALIDATION = 500 # reduce for test\n",
    "N_TEST = 500 # reduce for test\n",
    "VALIDATION_TEST_FREQUENCY = 100 # every x iterations val and test are performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer(buffer_size=REPLAY_BUFFER_SIZE, \n",
    "                             prior_exp=PRIOROTIZED_REPLAY_EXPONENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warm-start the replay buffer with random episodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............We ran out of samples!\n",
      "........................We ran out of samples!\n",
      "...........We ran out of samples!\n",
      "...............................We ran out of samples!\n",
      "...............................................Average episode duration =  21.4921875\n"
     ]
    }
   ],
   "source": [
    "# Keep track of episode duration to compute average\n",
    "episode_durations = []\n",
    "for _ in range(WARM_START_EPISODES):\n",
    "    print('.', end='')\n",
    "    # Reset the environment to start a new episode\n",
    "    # classifier_state contains vector representation of state of the environment (depends on classifier)\n",
    "    # next_action_state contains vector representations of all actions available to be taken at the next step\n",
    "    classifier_state, next_action_state = env.reset()\n",
    "    terminal = False\n",
    "    episode_duration = 0\n",
    "    # before we reach a terminal state, make steps\n",
    "    while not terminal:\n",
    "        # Choose a random action\n",
    "        action = np.random.randint(0, env.n_actions)\n",
    "        # taken_action_state is a vector corresponding to a taken action\n",
    "        taken_action_state = next_action_state[:,action]\n",
    "        next_classifier_state, next_action_state, reward, terminal = env.step(action)\n",
    "        # Store the transition in the replay buffer\n",
    "        replay_buffer.store_transition(classifier_state, \n",
    "                                       taken_action_state, \n",
    "                                       reward, next_classifier_state, \n",
    "                                       next_action_state, terminal)\n",
    "        # Get ready for next step\n",
    "        classifier_state = next_classifier_state\n",
    "        episode_duration += 1 \n",
    "    episode_durations.append(episode_duration)\n",
    "# compute the average episode duration of episodes generated during the warm start procedure\n",
    "av_episode_duration = np.mean(episode_durations)\n",
    "print('Average episode duration = ', av_episode_duration)\n",
    "\n",
    "BIAS_INITIALIZATION = -av_episode_duration/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the DQN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/seungbo/DRL/LAL-RL/dqn.py:57: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seungbo/DRL/LAL-RL/dqn.py:63: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seungbo/DRL/LAL-RL/estimator.py:38: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/seungbo/anaconda3/envs/DRL/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/seungbo/DRL/LAL-RL/estimator.py:77: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seungbo/DRL/LAL-RL/estimator.py:78: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seungbo/DRL/LAL-RL/dqn.py:85: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/seungbo/DRL/LAL-RL/dqn.py:101: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seungbo/DRL/LAL-RL/dqn.py:102: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seungbo/DRL/LAL-RL/dqn.py:113: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seungbo/DRL/LAL-RL/dqn.py:113: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seungbo/DRL/LAL-RL/dqn.py:118: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent = DQN(experiment_dir=DIRNAME,\n",
    "            observation_length=N_STATE_ESTIMATION,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            target_copy_factor=TARGET_COPY_FACTOR,\n",
    "            bias_average=BIAS_INITIALIZATION,\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do updates of the network based on warm start episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".WARNING:tensorflow:From /home/seungbo/DRL/LAL-RL/dqn.py:134: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "..................................................................................................."
     ]
    }
   ],
   "source": [
    "for _ in range(NN_UPDATES_PER_WARM_START):\n",
    "    print('.', end='')\n",
    "    # Sample a batch from the replay buffer proportionally to the probability of sampling.\n",
    "    minibatch = replay_buffer.sample_minibatch(BATCH_SIZE)\n",
    "    # Use batch to train an agent. Keep track of temporal difference errors during training.\n",
    "    td_error = agent.train(minibatch)\n",
    "    # Update probabilities of sampling each datapoint proportionally to the error.\n",
    "    replay_buffer.update_td_errors(td_error, minibatch.indeces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run multiple training iterations. Each iteration consits of:\n",
    "- generating episodes following agent's actions with exploration\n",
    "- validation and test episodes for evaluating performance\n",
    "- Q-network updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episode_rewards = []\n",
    "i_episode = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ..........We ran out of samples!\n",
      "We ran out of samples!\n",
      "We ran out of samples!\n",
      "We ran out of samples!\n",
      "We ran out of samples!\n",
      "We ran out of samples!\n",
      "1: ..........2: ..........3: ..........4: ..........5: ..........6: ......We ran out of samples!\n",
      "....7: ..........8: ..........9: ..........10: ..........11: ..........12: ..........13: ..........14: ..........15: ..........16: ..........17: ..........18: ..........19: ..........20: ..........21: ..........22: ..........23: .......We ran out of samples!\n",
      "...24: ..........25: .We ran out of samples!\n",
      ".........26: ..........27: ..........28: ..........29: ..........30: ..........31: ..........32: ..........33: ..........34: ..........35: ..........36: ..........37: ..........38: ..........39: ..........40: ..........41: ..........42: ..........43: ..........44: ..........45: ..........46: ..........47: ..........48: ..........49: ..........50: .....We ran out of samples!\n",
      ".....51: ..........52: ..........53: ..........54: ..........55: ..........56: ..........57: ..........58: ..........59: ..........60: ..........61: ..........62: ..........63: ..........64: ..........65: ..........66: ..........67: ..........68: ..........69: ..........70: ..........71: ..........72: ..........73: ..........74: ..........75: ..........76: ..........77: ..........78: ..........79: ..........80: ..........81: ..........82: ..........83: ..........84: ..........85: ..........86: ..........87: ..........88: ..........89: ..........90: ..........91: ..........92: ..........93: .......We ran out of samples!\n",
      "...94: ..........95: ..........96: ..........97: ..........98: ..........99: ..........100: ..........We ran out of samples!\n",
      "We ran out of samples!\n",
      "101: ..........102: ..........103: ..........104: ..........105: ..........106: ..........107: ..........108: ..........109: .........We ran out of samples!\n",
      ".110: ..........111: ..........112: ..........113: ..........114: ..........115: ..........116: ..........117: ..........118: ..........119: ..........120: ..........121: ..........122: ..........123: ..........124: .We ran out of samples!\n",
      ".........125: ..........126: ..........127: ..........128: ..........129: ..........130: ..........131: ..........132: ..........133: ..........134: ..........135: ..........136: ..........137: ..........138: ..........139: ..........140: ..........141: ..........142: .........We ran out of samples!\n",
      ".143: ..........144: ..........145: ..........146: ..........147: ..........148: ..........149: ..........150: ..........151: ..........152: ..........153: ..........154: ..........155: ..........156: ..........157: ..........158: ..........159: ..........160: ..........161: ..........162: ..........163: ..........164: ......We ran out of samples!\n",
      "....165: ..........166: ..........167: .We ran out of samples!\n",
      ".........168: ..........169: ..........170: ..........171: ..........172: ..........173: ..........174: ..........175: ..........176: ..........177: ..........178: ..........179: ..........180: ..........181: ..........182: ..........183: ..........184: ..........185: ..........186: ..........187: ..........188: ..........189: ..........190: ..........191: ..........192: ..........193: ..........194: ..........195: ..........196: ..........197: ..........198: ..........199: ..........200: ..........We ran out of samples!\n",
      "We ran out of samples!\n",
      "We ran out of samples!\n",
      "201: ..........202: ..........203: ..........204: ..........205: ..........206: ..........207: ..........208: ..........209: ..........210: ..........211: ..........212: ..........213: ..........214: ..........215: ..........216: ..........217: ..........218: ..........219: ..........220: ..........221: ..........222: ..........223: ..........224: ..........225: ..........226: ..........227: ..........228: ..........229: ..........230: ..........231: ..........232: ..We ran out of samples!\n",
      "........233: ..........234: ..........235: ..........236: ..........237: ..........238: ..........239: ..........240: ..We ran out of samples!\n",
      "........241: ..........242: ..........243: ..........244: ..........245: ..........246: ..........247: ..........248: ..........249: ..........250: ..........251: ..........252: ..........253: ..........254: ..........255: ..........256: ..........257: ..........258: ..........259: ..........260: ..........261: ..........262: ..........263: ..........264: ..........265: ..........266: ..........267: ..........268: ..........269: ..........270: ..........271: ..........272: ..........273: ..........274: ..........275: ..........276: ..We ran out of samples!\n",
      "........277: ..........278: ..........279: ..........280: .We ran out of samples!\n",
      ".........281: ..........282: ..........283: ..........284: ..........285: ..........286: ..........287: ..........288: ...We ran out of samples!\n",
      ".......289: ..........290: ..........291: ..........292: ..........293: ..........294: ..........295: ..........296: ..........297: ..........298: ..........299: ..........300: ..........We ran out of samples!\n",
      "We ran out of samples!\n",
      "We ran out of samples!\n",
      "We ran out of samples!\n",
      "We ran out of samples!\n",
      "We ran out of samples!\n",
      "We ran out of samples!\n",
      "301: ..........302: ..........303: ..........304: .........We ran out of samples!\n",
      ".305: ..........306: ..........307: ..........308: ..........309: ..........310: ..........311: ..........312: ..........313: ..........314: ..........315: ..........316: ..........317: ..........318: ..........319: ..........320: ..........321: ..........322: ..........323: ..........324: ..........325: ..........326: ..........327: ..........328: ..........329: ..........330: ..........331: ..........332: ..........333: ..........334: .We ran out of samples!\n",
      ".....We ran out of samples!\n",
      "....335: ..........336: ..........337: ..........338: ..........339: ..........340: ..........341: ..........342: ..........343: ..........344: ..........345: ..........346: ..........347: ..........348: ..We ran out of samples!\n",
      "........349: ..........350: ..........351: ..........352: ..........353: ..........354: ..........355: ..........356: ..........357: ..........358: ..........359: ..........360: ..........361: ..........362: ..........363: ..........364: ..........365: ..........366: ..........367: ..........368: ..........369: ..........370: ..........371: ..........372: ..........373: ..........374: ..........375: ..........376: ..........377: ..........378: ..........379: ..........380: ..........381: ..........382: ..........383: ..........384: ..........385: ..........386: ..........387: ..........388: ..........389: ..........390: ..........391: ..........392: ..........393: ..........394: ..........395: ..........396: ..........397: ..........398: ..........399: ..........400: ..........We ran out of samples!\n",
      "We ran out of samples!\n",
      "401: ..........402: ..........403: ..........404: ..........405: ..........406: ..........407: ..........408: ..........409: ..........410: ..........411: ..........412: ..........413: ..........414: ..........415: ..........416: ..........417: ..........418: ..........419: ..........420: ..........421: ..........422: ..........423: ...We ran out of samples!\n",
      ".......424: ..........425: ..........426: ..........427: ..........428: ..........429: ..........430: ..........431: ..........432: ..........433: ..........434: ..........435: ..........436: ..........437: ..........438: ..........439: ..........440: ..........441: ..........442: ..........443: ..........444: ..........445: ..........446: ..........447: ..........448: ..........449: ..........450: ..........451: ..........452: ..........453: ..........454: ..........455: ..........456: ..........457: ..........458: ..........459: ..........460: ..........461: ..........462: ..........463: ..........464: ..........465: ..........466: ..........467: ..........468: ..........469: ..........470: ..........471: ..........472: ..........473: ..........474: ..........475: ..........476: ..........477: ..........478: ..........479: ..........480: ..........481: ..........482: ..........We ran out of samples!\n",
      "483: ..........484: ..........485: ..........486: ..........487: ..........488: ..........489: ..........490: ..........491: ..........492: ..........493: ..........494: ..........495: ..........496: ..........497: ..We ran out of samples!\n",
      "........498: ..........499: ..........500: ..........501: ..........502: ..........503: ..........504: ..........505: ..........506: ..........507: ..........508: ..........509: ..........510: ..........511: ..........512: ..........513: ..........514: ..........515: ..........516: ..........517: ..........518: ..........519: ..........520: ..........521: ..........522: ..........523: ..........524: ..........525: ..........526: ..........527: ..........528: ..........529: ..........530: ..........531: ..........532: ..........533: ..........534: ..........535: ..........536: ..........537: ..........538: ..........539: ..........540: ..........541: ..........542: ..........543: ..........544: ..........545: ..We ran out of samples!\n",
      "........546: ..........547: ..........548: ..........549: ..........550: ..........551: ..........552: ..........553: ..........554: ..........555: ..........556: ..........557: ..........558: ..........559: ..........560: ..........561: ..........562: ..........563: ..........564: ..........565: ..........566: ..........567: ..........568: ..........569: ..........570: ..........571: ..........572: ..........573: ..........574: ..........575: ..........576: ..........577: ..........578: ..........579: ..........580: ..........581: ..........582: ..........583: ..........584: ..........585: ..........586: ..........587: ..........588: ..........589: ..........590: ..........591: ..........592: ..........593: ..........594: ..........595: ..........596: ..........597: ..........598: ..........599: ..........600: ..........We ran out of samples!\n",
      "We ran out of samples!\n",
      "We ran out of samples!\n",
      "601: ..........602: ..........603: ..........604: ..........605: ..........606: ..........607: ..........608: ..........609: ..........610: ..........611: ..........612: ..........613: ..........614: ..........615: ..........616: ..........617: ..........618: ..........619: ..........620: ..........621: ..........622: ..........623: ..........624: ..........625: ..........626: ..........627: ..........628: ..........629: ..........630: ..........631: ..........632: ..........633: ..........634: ..........635: ..........636: ......We ran out of samples!\n",
      "....637: ..........638: ..........639: ..........640: ..........641: ..........642: ..........643: ..........644: ..........645: ..........646: ..........647: ..........648: ..........649: ..........650: ..........651: ..........652: ..........653: ..........654: ..........655: .We ran out of samples!\n",
      ".........656: ..........657: ..........658: ..........659: ..........660: ..........661: ..........662: ..........663: ..........664: ..........665: ..........666: ..........667: ..........668: ..........669: ..........670: ..........671: ..........672: ..........673: ..........674: ..........675: ..........676: ..........677: ..........678: ..........679: ..........680: ..........681: ..........682: ..........683: ..........684: ..........685: ..........686: ..........687: ..........688: ..........689: ..........690: ..........691: ..........692: ..........693: ..........694: ..........695: ..........696: ..........697: ..........698: ..........699: ..........700: ..........We ran out of samples!\n",
      "We ran out of samples!\n",
      "We ran out of samples!\n",
      "701: ..........702: ......We ran out of samples!\n",
      "....703: ..........704: ..........705: ..........706: ..........707: ..........708: ..........709: ..........710: ..........711: ..........712: .We ran out of samples!\n",
      ".........713: ..........714: ..........715: ..........716: ..........717: ..........718: ..........719: ..........720: ..........721: ..........722: ..........723: ..........724: ..........725: ..........726: ..........727: ..........728: ..........729: ..........We ran out of samples!\n",
      "730: ..........731: .....We ran out of samples!\n",
      ".....732: ..........733: ..........734: ..........735: ..........736: ..........737: ..........738: ..........739: ..........740: ..........741: ..........742: ..........743: ..........744: ..........745: ..........746: ..........747: ..........748: ..........749: ..........750: ..........751: ..........752: ...We ran out of samples!\n",
      ".......753: ..........754: ..........755: ..........756: ..........757: ..........758: ..........759: ..........760: ..........761: ..We ran out of samples!\n",
      "........762: ..........763: ..........764: ..........765: ..........766: ..........767: ..........768: ..........769: ..........770: ..........771: ..........772: ..........773: ..........774: ..........775: ..........776: ..........777: ..........778: ..........779: ..........780: ..........781: ..........782: ..........783: ..........784: ..........785: ..........786: ..........787: ..........788: ..........789: ..........790: ..........791: ..........792: ..........793: ..........794: ..........795: ..........796: ..........797: ..........798: ..........799: ..........800: ..........We ran out of samples!\n",
      "We ran out of samples!\n",
      "We ran out of samples!\n",
      "We ran out of samples!\n",
      "801: ..........802: ..........803: ..........804: ..........805: ..........806: ..........807: ..........808: ..........809: ..........810: ..........811: ...We ran out of samples!\n",
      ".......812: ..........813: ..........814: ..........815: ..........816: ..........817: ..........818: ..........819: ..........820: ..........821: ..........822: ..........823: ..........824: ..........825: ..........826: ..........827: ..........828: ..........829: ..........830: ..........831: ..........832: ..........833: ..........834: ..........835: ..........836: ..........837: ..........838: ..........839: ..........840: ..........841: ..........842: ..........843: .......We ran out of samples!\n",
      "...844: ..........845: ..........846: ..........847: ..........848: ..........849: ..........850: ..........851: ..........852: ..........853: ..........854: ..........855: ..........856: ..........857: ..........858: ..........859: ..........860: ..........861: ..........862: ..........863: ..........864: ..........865: ..........866: ..........867: ..........868: ..........869: ..........870: ..........871: ..........872: ........We ran out of samples!\n",
      "..873: ..........874: ..........875: ..........876: ..........877: ..........878: ..........879: ..........880: ..........881: ..........882: ..........883: ..........884: ..........885: ..........886: ..........887: ..........888: ..........889: ..........890: ..........891: ..........892: ..........893: ..........894: ..........895: ..........896: ..........897: ..........898: ..........899: ......We ran out of samples!\n",
      "....900: ..........We ran out of samples!\n",
      "901: ..........902: ..........903: ..........904: ..........905: ..........906: ..........907: ..........908: ..........909: ..........910: ..........911: ..........912: ..........913: ..........914: ..........915: ..........916: ..........917: ..........918: ..........919: ..........920: ..........921: ..........922: ..........923: ..........924: ....We ran out of samples!\n",
      "......925: ..........926: ..........927: ..........928: ..........929: ..........930: ..........931: ..........932: ..........933: ..........934: ..........935: ..........936: ..........937: ..........938: ..........939: ..........940: ..........941: ..........942: ..........943: ..........944: ..........945: ..........946: ..........947: ..........948: ..........949: ..........950: ..........951: ..........952: ..........953: ..........954: ..........955: ..........956: ..........957: ..........958: ..........959: ..........960: ..........961: ..........962: ..........963: ..........964: ..........965: ..........966: ..........967: ..........968: ..........969: ..We ran out of samples!\n",
      "........970: ..........971: ..........972: ..........973: ..........974: ..........975: ..........976: ..........977: ..........978: ..........979: ..........980: ..........981: ..........982: ..........983: ..........984: ..........985: ..........986: ..........987: ......We ran out of samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....988: ..........989: ..........990: ..........991: ..........992: ..........993: ..........994: ..........995: ..........996: ..........997: ..........998: ..........999: .........."
     ]
    }
   ],
   "source": [
    "for iteration in range(TRAINING_ITERATIONS):\n",
    "    # GENERATE NEW EPISODES\n",
    "    # Compute epsilon value according to the schedule.\n",
    "    epsilon = max(EPSILON_END, EPSILON_START-iteration*(EPSILON_START-EPSILON_END)/EPSILON_STEPS)\n",
    "    print(iteration, end=': ')\n",
    "    # Simulate training episodes.\n",
    "    for _ in range(TRAINING_EPISODES_PER_ITERATION):\n",
    "        # Reset the environment to start a new episode.\n",
    "        classifier_state, next_action_state = env.reset()\n",
    "        print(\".\", end='')\n",
    "        terminal = False\n",
    "        # Keep track of stats of episode to analyse it in tensorboard.\n",
    "        episode_reward = 0\n",
    "        episode_duration = 0\n",
    "        episode_summary = tf.Summary()\n",
    "        # Run an episode.\n",
    "        while not terminal:\n",
    "            # Let an agent choose an action.\n",
    "            action = agent.get_action(classifier_state, next_action_state)\n",
    "            # Get a prob of a datapoint corresponding to an action chosen by an agent.\n",
    "            # It is needed just for the tensorboard analysis.\n",
    "            rlchosen_action_state = next_action_state[0,action]\n",
    "            # With epsilon probability, take a random action.\n",
    "            if np.random.ranf() < epsilon: \n",
    "                action = np.random.randint(0, env.n_actions)\n",
    "            # taken_action_state is a vector that corresponds to a taken action\n",
    "            taken_action_state = next_action_state[:,action]\n",
    "            # Make another step.\n",
    "            next_classifier_state, next_action_state, reward, terminal = env.step(action)\n",
    "            # Store a step in replay buffer\n",
    "            replay_buffer.store_transition(classifier_state, \n",
    "                                           taken_action_state, \n",
    "                                           reward, \n",
    "                                           next_classifier_state, \n",
    "                                           next_action_state, \n",
    "                                           terminal)\n",
    "            # Change a state of environment.\n",
    "            classifier_state = next_classifier_state\n",
    "            # Keep track of stats and add summaries to tensorboard.\n",
    "            episode_reward += reward\n",
    "            episode_duration += 1\n",
    "            episode_summary.value.add(simple_value=rlchosen_action_state, \n",
    "                                      tag=\"episode/rlchosen_action_state\")\n",
    "            episode_summary.value.add(simple_value=taken_action_state[0], \n",
    "                                      tag=\"episode/taken_action_state\")\n",
    "        # Add summaries to tensorboard\n",
    "        episode_summary.value.add(simple_value=episode_reward, \n",
    "                                  tag=\"episode/episode_reward\")\n",
    "        episode_summary.value.add(simple_value=episode_duration, \n",
    "                                  tag=\"episode/episode_duration\")\n",
    "        i_episode += 1\n",
    "        agent.summary_writer.add_summary(episode_summary, i_episode)\n",
    "        agent.summary_writer.flush()\n",
    "        \n",
    "    # VALIDATION AND TEST EPISODES\n",
    "    episode_summary = tf.Summary()\n",
    "    if iteration%VALIDATION_TEST_FREQUENCY == 0:\n",
    "        # Validation episodes are run. Use env for it.\n",
    "        all_durations = []\n",
    "        for i in range(N_VALIDATION):\n",
    "            done = False\n",
    "            state, next_action_state = env.reset()\n",
    "            while not(done):\n",
    "                action = policy_rl(agent, state, next_action_state)        \n",
    "                taken_action_state = next_action_state[:,action]\n",
    "                next_state, next_action_state, reward, done = env.step(action)\n",
    "                state = next_state\n",
    "            all_durations.append(len(env.episode_qualities))\n",
    "        episode_summary.value.add(simple_value=np.mean(all_durations), \n",
    "                                  tag=\"episode/train_duration\")\n",
    "        # Test episodes are run. Use env_test for it.\n",
    "        all_durations = []\n",
    "        for i in range(N_TEST):\n",
    "            done = False\n",
    "            state, next_action_state = env_test.reset()\n",
    "            while not(done):\n",
    "                action = policy_rl(agent, state, next_action_state)        \n",
    "                taken_action_state = next_action_state[:,action]\n",
    "                next_state, next_action_state, reward, done = env_test.step(action)\n",
    "                state = next_state\n",
    "            all_durations.append(len(env_test.episode_qualities))\n",
    "        episode_summary.value.add(simple_value=np.mean(all_durations), \n",
    "                                  tag=\"episode/test_duration\")\n",
    "    \n",
    "    episode_summary.value.add(simple_value=epsilon, \n",
    "                              tag=\"episode/epsilon\")\n",
    "    agent.summary_writer.add_summary(episode_summary, iteration)\n",
    "    agent.summary_writer.flush()\n",
    "            \n",
    "    # NEURAL NETWORK UPDATES\n",
    "    for _ in range(NN_UPDATES_PER_ITERATION):\n",
    "        minibatch = replay_buffer.sample_minibatch(BATCH_SIZE)\n",
    "        td_error = agent.train(minibatch)\n",
    "        replay_buffer.update_td_errors(td_error, minibatch.indeces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### To see the results in tensorboard\n",
    "\n",
    "on the server:\n",
    "tensorboard --logdir=./\n",
    "\n",
    "on the computer:\n",
    "ssh -N -f -L localhost:6006:localhost:6006 konyushk@iccvlabsrv20.iccluster.epfl.ch && open http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
